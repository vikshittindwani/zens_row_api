{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFVGXuZpoS8I"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "ZENROWS_API_KEY = \"08d0a56ec34e95b3cd4f6458558356ceb36596d1\"  # Replace with your key\n",
        "PRODUCT_URL = \"https://www.walmart.com/ip/Gucci-Flora-Gorgeous-Magnolia-for-Women-3-3-oz-EDP-Spray-New-Tester/14918266812?classType=REGULAR\"  # Replace with your product URL\n",
        "\n",
        "params = {\n",
        "    \"url\": PRODUCT_URL,\n",
        "    \"apikey\": ZENROWS_API_KEY,\n",
        "    \"js_render\": True,\n",
        "    \"premium_proxy\": \"true\"\n",
        "}\n",
        "\n",
        "response = requests.get(\"https://api.zenrows.com/v1/\", params=params)\n",
        "\n",
        "def extract_site_name(url):\n",
        "    domain = urlparse(url).netloc\n",
        "    if \"amazon\" in domain:\n",
        "        return \"amazon\"\n",
        "    elif \"ebay\" in domain:\n",
        "        return \"ebay\"\n",
        "    elif \"alibaba\" in domain:\n",
        "        return \"alibaba\"\n",
        "    return \"unknown\"\n",
        "\n",
        "def extract_title(soup, site):\n",
        "    if site == \"amazon\":\n",
        "        tag = soup.find(\"span\", id=\"productTitle\")\n",
        "    elif site == \"ebay\":\n",
        "        tag = soup.find(\"h1\", id=\"itemTitle\") or soup.find(\"h1\", class_=re.compile(\"mainTitle\"))\n",
        "        if tag:\n",
        "            return tag.get_text(strip=True).replace(\"Details about  \\xa0\", \"\")\n",
        "    elif site == \"alibaba\":\n",
        "        tag = soup.find(\"h1\", class_=re.compile(\"ma-title\")) or soup.find(\"h1\")\n",
        "    else:\n",
        "        tag = soup.find(\"title\")\n",
        "    return tag.get_text(strip=True) if tag else \"Title not found\"\n",
        "\n",
        "def extract_price(soup, site):\n",
        "    if site == \"amazon\":\n",
        "# Amazon usually splits price into whole and fraction\n",
        "     whole = soup.find(\"span\", class_=\"a-price-whole\")\n",
        "     fraction = soup.find(\"span\", class_=\"a-price-fraction\")\n",
        "     if whole:\n",
        "       return f\"{whole.get_text(strip=True)}.{fraction.get_text(strip=True) if fraction else '00'}\"\n",
        "\n",
        "    elif site == \"alibaba\":\n",
        "    # Match span with data-spm-anchor-id and $ inside\n",
        "        tag = soup.find(\"div\", class_=re.compile(\"price\", re.IGNORECASE))\n",
        "        if tag:\n",
        "            text = tag.get_text(strip=True)\n",
        "            if \"$\" in text:\n",
        "                return text\n",
        "        return \"Price not found\"\n",
        "\n",
        "    elif site == \"ebay\":\n",
        "    # Match span with class ux-textspans that contains a price\n",
        "        tags = soup.find_all(\"span\", class_=\"ux-textspans\")\n",
        "        for tag in tags:\n",
        "            text = tag.get_text(strip=True)\n",
        "            if re.search(r\"\\$\\d\", text):\n",
        "                return text\n",
        "\n",
        "    return \"Price not found\"\n",
        "\n",
        "\n",
        "def extract_images(soup):\n",
        "    images = []\n",
        "    for img in soup.find_all(\"img\"):\n",
        "        src = img.get(\"src\") or img.get(\"data-src\")\n",
        "        if src and \".jpg\" in src.lower():\n",
        "            if src.startswith(\"//\"):\n",
        "                src = \"https:\" + src\n",
        "            high_res_src = re.sub(r'\\._[A-Z0-9,_]+\\_', '', src)\n",
        "            images.append(high_res_src)\n",
        "    return list(dict.fromkeys(images))  # remove duplicates\n",
        "\n",
        "def extract_videos(soup):\n",
        "    videos = []\n",
        "    for video_tag in soup.find_all(\"video\"):\n",
        "        src = video_tag.get(\"src\")\n",
        "        if src and \".mp4\" in src:\n",
        "            videos.append(\"https:\" + src if src.startswith(\"//\") else src)\n",
        "    for source in soup.find_all(\"source\"):\n",
        "        src = source.get(\"src\")\n",
        "        if src and \".mp4\" in src:\n",
        "            videos.append(\"https:\" + src if src.startswith(\"//\") else src)\n",
        "    return list(set(videos))\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    site = extract_site_name(PRODUCT_URL)\n",
        "\n",
        "    title = extract_title(soup, site)\n",
        "    price = extract_price(soup, site)\n",
        "    images = extract_images(soup)\n",
        "    videos = extract_videos(soup)\n",
        "\n",
        "    # ‚úÖ Output\n",
        "    print(\"üîπ Site:\", site)\n",
        "    print(\"üõí Title:\", title)\n",
        "    print(\"üí∞ Price:\", price)\n",
        "    print(\"üñºÔ∏è Images (Top 5):\", images[:5])\n",
        "    print(\"üé• Video URLs:\", videos if videos else \"No video found\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to fetch data\")\n",
        "    print(\"Status Code:\", response.status_code)\n",
        "    print(\"Response:\", response.text)\n"
      ]
    }
  ]
}